{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.system(\"git clone https://github.com/lorenzo-saccaro/NNDL-recoloring-GAN\")","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:40:02.671894Z","iopub.execute_input":"2023-01-04T17:40:02.672348Z","iopub.status.idle":"2023-01-04T17:40:03.575476Z","shell.execute_reply.started":"2023-01-04T17:40:02.672300Z","shell.execute_reply":"2023-01-04T17:40:03.574207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# check if in kaggle \nif 'KAGGLE_CONTAINER_NAME' in os.environ:\n    kaggle = True\n    os.chdir('/kaggle/working/NNDL-recoloring-GAN')\n    print(os.getcwd())\n    # pull repo to update .py files\n    os.system('git pull')\n    \nelse:\n    kaggle = False\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:40:04.865590Z","iopub.execute_input":"2023-01-04T17:40:04.866023Z","iopub.status.idle":"2023-01-04T17:40:05.231743Z","shell.execute_reply.started":"2023-01-04T17:40:04.865990Z","shell.execute_reply":"2023-01-04T17:40:05.230236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataset import CocoDataset\nfrom torchvision.transforms import Compose, ToTensor, Grayscale, Resize\nfrom torch.utils.data import DataLoader\nimport torch\nimport torch.nn as nn\nimport tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:40:06.412536Z","iopub.execute_input":"2023-01-04T17:40:06.412988Z","iopub.status.idle":"2023-01-04T17:40:07.539235Z","shell.execute_reply.started":"2023-01-04T17:40:06.412951Z","shell.execute_reply":"2023-01-04T17:40:07.538085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset creation","metadata":{}},{"cell_type":"code","source":"if kaggle:\n    DATASET_ROOT = '/kaggle/input/coco-2017-dataset/coco2017'\nelse:\n    DATASET_ROOT = 'C:\\\\Users\\\\loren\\\\Datasets\\\\coco2017'\n\nprint(DATASET_ROOT)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-04T17:40:08.513853Z","iopub.execute_input":"2023-01-04T17:40:08.514696Z","iopub.status.idle":"2023-01-04T17:40:08.520995Z","shell.execute_reply.started":"2023-01-04T17:40:08.514658Z","shell.execute_reply":"2023-01-04T17:40:08.519831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define transformations to apply to each dataset input and output","metadata":{}},{"cell_type":"code","source":"transform_x_train = Compose([\n    ToTensor(),\n    Resize((256,256)), # TODO: to be tuned\n    Grayscale() # TODO: think about other transformation / data augmentation techniques (be carefull that the transformation must be the same for x and y (eg. random ones, probably need to rewrite class)\n])\n\ntransform_y_train = Compose([\n    ToTensor(),\n    Resize((256,256)) # TODO: to be tuned\n])\n\n# TODO: think if transformations for val and test have to be different from the train one\ntransform_x_val = transform_x_test = transform_x_train\ntransform_y_val = transform_y_test = transform_y_train","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-04T17:40:09.148976Z","iopub.execute_input":"2023-01-04T17:40:09.149412Z","iopub.status.idle":"2023-01-04T17:40:09.156727Z","shell.execute_reply.started":"2023-01-04T17:40:09.149378Z","shell.execute_reply":"2023-01-04T17:40:09.155186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get dataset objects from helper function","metadata":{}},{"cell_type":"code","source":"train_dataset = CocoDataset(dataset_folder=DATASET_ROOT, dataset_type='train', transform_x=transform_x_train,\n                            transform_y=transform_y_train)\n\nval_dataset = CocoDataset(dataset_folder=DATASET_ROOT, dataset_type='val', transform_x=transform_x_val,\n                            transform_y=transform_y_val)\n\ntest_dataset = CocoDataset(dataset_folder=DATASET_ROOT, dataset_type='test', transform_x=transform_x_test,\n                            transform_y=transform_y_test)\n# TODO: Think about working in Lab colorspace and use just 2 vectors as output\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-04T17:40:09.813918Z","iopub.execute_input":"2023-01-04T17:40:09.814354Z","iopub.status.idle":"2023-01-04T17:40:11.799247Z","shell.execute_reply.started":"2023-01-04T17:40:09.814317Z","shell.execute_reply":"2023-01-04T17:40:11.798163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define corresponding dataloaders","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32 # TODO: to be tuned\n\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count())\n\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())\n\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())\n\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-04T17:40:11.800999Z","iopub.execute_input":"2023-01-04T17:40:11.801572Z","iopub.status.idle":"2023-01-04T17:40:11.807391Z","shell.execute_reply.started":"2023-01-04T17:40:11.801537Z","shell.execute_reply":"2023-01-04T17:40:11.806320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test if everything is working\niterator = tqdm.tqdm(train_dataloader)\nfor x_batch, y_batch in iterator:\n    pass\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-03T16:20:28.034275Z","iopub.execute_input":"2023-01-03T16:20:28.035196Z","iopub.status.idle":"2023-01-03T16:39:26.022504Z","shell.execute_reply.started":"2023-01-03T16:20:28.035125Z","shell.execute_reply":"2023-01-03T16:39:26.018970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Definition","metadata":{}},{"cell_type":"markdown","source":"### Generator","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    \n    def __init__(self, in_size, out_size, kernel = 3, padding = 1):\n        \n        super().__init__()\n        \n        self.conv_block = nn.Sequential(\n            nn.Conv2d(in_size, out_size, kernel_size=kernel, padding=padding),\n            nn.BatchNorm2d(out_size),\n            \n            nn.Conv2d(out_size, out_size, kernel_size=kernel, padding=padding),\n            nn.BatchNorm2d(out_size),\n            \n            nn.ReLU()\n            )\n        \n        self.apply(self._init_weights)\n    \n    def _init_weights(self, module):\n        if isinstance(module, nn.Conv2d):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.BatchNorm2d):\n            nn.init.normal_(module.weight.data, 1.0, 0.2)\n            nn.init.constant_(module.bias.data, 0)\n    \n    def forward(self, x):\n        \n        y = self.conv_block(x)\n\n        return y\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:57:40.119828Z","iopub.execute_input":"2023-01-04T17:57:40.120316Z","iopub.status.idle":"2023-01-04T17:57:40.131996Z","shell.execute_reply.started":"2023-01-04T17:57:40.120273Z","shell.execute_reply":"2023-01-04T17:57:40.130683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_b = ConvBlock(1, 64)\n\nfoo = torch.normal(0, 1, [1, 1, 256, 256])\nprint(foo.shape)\nresult = c_b(foo).detach()\nprint(result.shape)\nresult = result[0,1]\nprint(result.shape)\n\nplt.imshow(foo.squeeze(), cmap='gray')\nplt.figure()\nplt.imshow(result, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T18:28:42.901506Z","iopub.execute_input":"2023-01-04T18:28:42.901934Z","iopub.status.idle":"2023-01-04T18:28:43.356890Z","shell.execute_reply.started":"2023-01-04T18:28:42.901902Z","shell.execute_reply":"2023-01-04T18:28:43.355516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    \n    def __init__(self, in_size, out_size, pool_size = (2,2)):\n        \n        super().__init__()\n        \n        self.conv_block = ConvBlock(in_size, out_size)\n        self.pool = nn.MaxPool2d(pool_size)\n    \n        self.conv_block._init_weights\n    \n    def forward(self, x):\n        y = self.conv_block(x) # keep y since will be used for the decoder part\n        pooled = self.pool(y)\n        \n        return y, pooled","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:40:16.123494Z","iopub.execute_input":"2023-01-04T17:40:16.123967Z","iopub.status.idle":"2023-01-04T17:40:16.132853Z","shell.execute_reply.started":"2023-01-04T17:40:16.123929Z","shell.execute_reply":"2023-01-04T17:40:16.131709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, in_size, out_size, kernel = 2, padding = 1):\n        \n        super().__init__()\n        \n        self.t_conv = nn.ConvTranspose2d(in_size, out_size, kernel_size= kernel, padding=padding)\n        self.conv_block = ConvBlock(2*out_size, out_size)\n        \n        self.conv_block._init_weights()\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.ConvTranspose2d):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                module.bias.data.zero_()\n            \n\n    \n    def forward(self, x, skip):\n        y = self.t_conv(x)\n        y = torch.cat([skip, y], axis=1)\n        y = self.conv_block(y)\n        \n        return y","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:40:16.986407Z","iopub.execute_input":"2023-01-04T17:40:16.986856Z","iopub.status.idle":"2023-01-04T17:40:16.995856Z","shell.execute_reply.started":"2023-01-04T17:40:16.986819Z","shell.execute_reply":"2023-01-04T17:40:16.994539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, in_size):\n        \n        super().__init__()\n        \n        self.e1 = EncoderBlock(in_size, 64)\n        self.e2 = EncoderBlock(64, 128)\n        self.e3 = EncoderBlock(128, 256)\n        self.e4 = EncoderBlock(256,512)\n        \n        self.bottleneck = ConvBlock(512,1024)\n        \n        self.d4 = DecoderBlock(1024,512)\n        self.d3 = DecoderBlock(512,256)\n        self.d2 = DecoderBlock(256,128)\n        self.d1 = DecoderBlock(128,64)\n        \n        self.last = nn.Conv2d(64, 3, kernel_size=1, padding=0)\n        \n        def _init_weights():\n            \n    \n        \n    def forward(self,x):\n        y, p1 = self.e1(x)\n        y, p2 = self.e2(y)\n        y, p3 = self.e3(y)\n        y, p4 = self.e4(y)\n        y = self.bottleneck(y)\n        y = self.d4(y, p4)\n        y = self.d3(y, p3)\n        y = self.d2(y, p2)\n        y = self.d1(y, p1)\n        y = self.last(y)\n        \n        return y\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-04T17:40:19.281907Z","iopub.execute_input":"2023-01-04T17:40:19.282544Z","iopub.status.idle":"2023-01-04T17:40:19.294698Z","shell.execute_reply.started":"2023-01-04T17:40:19.282501Z","shell.execute_reply":"2023-01-04T17:40:19.293362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#class UNet(nn.Module):\n#    def __init__(self, in_size, out_size):\n#        \n#        super.__init__()\n#        \n#        self.unet = nn.Sequential(\n#            EncoderBlock(in_size, 64),\n#            EncoderBlock(64, 128),\n#            EncoderBlock(128, 256),\n#            EncoderBlock(256,512),\n#        \n#            ConvBlock(512,1024),\n#        \n#            DecoderBlock(1024,512),\n#            DecoderBlock(512,256),\n#            DecoderBlock(256,128),\n#            DecoderBlock(128,64),\n#        \n#            nn.Conv2d(64, 2, kernel_size=1, padding=0)\n#        )\n#        \n#    def forward(self,data_input):\n#        self.unet(data_input)\n#        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initialize weights and try to produce noisy image","metadata":{}},{"cell_type":"code","source":"image, colored = test_dataset.__getitem__(10)\nplt.imshow(colored.permute(1, 2, 0))\n#plt.imshow(image.squeeze(0), cmap='binary_r')\nprint(image.shape, colored.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T15:53:10.863477Z","iopub.execute_input":"2023-01-04T15:53:10.863897Z","iopub.status.idle":"2023-01-04T15:53:11.131355Z","shell.execute_reply.started":"2023-01-04T15:53:10.863862Z","shell.execute_reply":"2023-01-04T15:53:11.130571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = UNet(100)\ngenerator.apply(weights_init)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:06:51.018899Z","iopub.execute_input":"2023-01-04T11:06:51.019326Z","iopub.status.idle":"2023-01-04T11:06:51.357186Z","shell.execute_reply.started":"2023-01-04T11:06:51.019290Z","shell.execute_reply":"2023-01-04T11:06:51.355525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}